---
tags:
  - Lesson
  - sequential_data
---
[[Markov Chain]] in Bayesian statistics we used the chain to sample to find the correct distribution 
here we are assuming the data is a Markov chain, todays wether will help predict tomorrows weather

$2^{nd}$ order Markov Chain says the information on the last point isn't enough to predict the next point, we also need the point before the previous

$Z$ values are typically hidden from us

$\pi$ is the probabilities of this initial state $z_1$
a transition matrix for a mixture model would have all rows looking the same as data is independent

english language makes sequential text difficult as it has a lot of ambiguity when it comes to nouns, verbs, etc

[[EM algorithm]]